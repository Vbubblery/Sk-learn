{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Session Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and parse the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "#sample characteristics\n",
    "iris_X = iris.data\n",
    "# The variety of flowers \n",
    "iris_y = iris.target\n",
    "np.unique(iris_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split iris data in train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A random permutation, to split the data randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114  62  33 107   7 100  40  86  76  71 134  51  73  54  63  37  78  90\n",
      "  45  16 121  66  24   8 126  22  44  97  93  26 137  84  27 127 132  59\n",
      "  18  83  61  92 112   2 141  43  10  60 116 144 119 108  69 135  56  80\n",
      " 123 133 106 146  50 147  85  30 101  94  64  89  91 125  48  13 111  95\n",
      "  20  15  52   3 149  98   6  68 109  96  12 102 120 104 128  46  11 110\n",
      " 124  41 148   1 113 139  42   4 129  17  38   5  53 143 105   0  34  28\n",
      "  55  75  35  23  74  31 118  57 131  65  32 138  14 122  19  29 130  49\n",
      " 136  99  82  79 115 145  72  77  25  81 140 142  39  58  88  70  87  36\n",
      "  21   9 103  67 117  47]\n"
     ]
    }
   ],
   "source": [
    "# Set a random array, the size of array is length of iris_X\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "print (indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.1  2.6  5.6  1.4]\n"
     ]
    }
   ],
   "source": [
    "iris_X_train = iris_X[indices[:-10]]\n",
    "iris_y_train = iris_y[indices[:-10]]\n",
    "iris_X_test = iris_X[indices[-10:]]\n",
    "iris_y_test = iris_y[indices[-10:]]\n",
    "print (iris_X[indices[10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a k-nearest-neighbor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit a k-nearest-neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# if we set the num of neighbirs as 8, the result will be 100%, default is 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# Learn how to classfier according to the iris_X_train and iris_y_train\n",
    "knn.fit(iris_X_train, iris_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## evaluate model on test instances and compute test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "knn.predict(iris_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The really result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(iris_y_test,knn.predict(iris_X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a jupyter notebook with the following tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write error of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = 1 - accuracy_score(iris_y_test,knn.predict(iris_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when the number of neghbor is 5, error rate : 0.09999999999999998 \n"
     ]
    }
   ],
   "source": [
    "print (\"when the number of neghbor is 5, error rate : {0} \".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What is the optimal parameter k of the k'nearest-neighbor classifier for this dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal k is : 8 with 1.0\n",
      "The optimal k is : 9 with 1.0\n",
      "The optimal k is : 10 with 1.0\n",
      "The optimal k is : 11 with 1.0\n",
      "The optimal k is : 12 with 1.0\n",
      "The optimal k is : 14 with 1.0\n",
      "The optimal k is : 16 with 1.0\n",
      "The optimal k is : 17 with 1.0\n",
      "The optimal k is : 18 with 1.0\n",
      "The optimal k is : 19 with 1.0\n",
      "The optimal k is : 20 with 1.0\n",
      "The optimal k is : 21 with 1.0\n",
      "The optimal k is : 22 with 1.0\n",
      "The optimal k is : 23 with 1.0\n",
      "The optimal k is : 24 with 1.0\n",
      "The optimal k is : 26 with 1.0\n",
      "The optimal k is : 27 with 1.0\n",
      "The optimal k is : 28 with 1.0\n",
      "The optimal k is : 29 with 1.0\n",
      "The optimal k is : 30 with 1.0\n",
      "The optimal k is : 31 with 1.0\n",
      "The optimal k is : 32 with 1.0\n",
      "The optimal k is : 33 with 1.0\n",
      "The optimal k is : 34 with 1.0\n",
      "The optimal k is : 35 with 1.0\n",
      "The optimal k is : 36 with 1.0\n",
      "The optimal k is : 37 with 1.0\n",
      "The optimal k is : 38 with 1.0\n",
      "The optimal k is : 39 with 1.0\n",
      "The optimal k is : 40 with 1.0\n",
      "The optimal k is : 41 with 1.0\n",
      "The optimal k is : 42 with 1.0\n",
      "The optimal k is : 43 with 1.0\n",
      "The optimal k is : 44 with 1.0\n",
      "The optimal k is : 45 with 1.0\n",
      "The optimal k is : 46 with 1.0\n",
      "The optimal k is : 47 with 1.0\n",
      "The optimal k is : 48 with 1.0\n",
      "The optimal k is : 49 with 1.0\n",
      "The optimal k is : 50 with 1.0\n",
      "The optimal k is : 51 with 1.0\n",
      "The optimal k is : 52 with 1.0\n",
      "The optimal k is : 53 with 1.0\n",
      "The optimal k is : 54 with 1.0\n",
      "The optimal k is : 55 with 1.0\n",
      "The optimal k is : 56 with 1.0\n",
      "The optimal k is : 57 with 1.0\n",
      "The optimal k is : 58 with 1.0\n",
      "The optimal k is : 59 with 1.0\n",
      "The optimal k is : 60 with 1.0\n",
      "The optimal k is : 61 with 1.0\n",
      "The optimal k is : 62 with 1.0\n",
      "The optimal k is : 63 with 1.0\n",
      "The optimal k is : 64 with 1.0\n",
      "The optimal k is : 65 with 1.0\n",
      "The optimal k is : 66 with 1.0\n",
      "The optimal k is : 67 with 1.0\n",
      "The optimal k is : 68 with 1.0\n",
      "The optimal k is : 69 with 1.0\n",
      "The optimal k is : 70 with 1.0\n",
      "The optimal k is : 71 with 1.0\n",
      "The optimal k is : 72 with 1.0\n",
      "The optimal k is : 73 with 1.0\n",
      "The optimal k is : 74 with 1.0\n",
      "The optimal k is : 75 with 1.0\n",
      "The optimal k is : 76 with 1.0\n",
      "The optimal k is : 77 with 1.0\n",
      "The optimal k is : 78 with 1.0\n",
      "The optimal k is : 79 with 1.0\n",
      "The optimal k is : 80 with 1.0\n",
      "The optimal k is : 81 with 1.0\n",
      "The optimal k is : 82 with 1.0\n",
      "The optimal k is : 83 with 1.0\n",
      "The optimal k is : 84 with 1.0\n",
      "The optimal k is : 86 with 1.0\n",
      "The optimal k is : 87 with 1.0\n",
      "The optimal k is : 88 with 1.0\n",
      "The optimal k is : 89 with 1.0\n",
      "The optimal k is : 90 with 1.0\n",
      "The optimal k is : 91 with 1.0\n",
      "The optimal k is : 92 with 1.0\n"
     ]
    }
   ],
   "source": [
    "tab = dict()\n",
    "i=1\n",
    "while i<=(len(iris_X_train)):\n",
    "    k = KNeighborsClassifier(n_neighbors=i)\n",
    "    k.fit(iris_X_train, iris_y_train)\n",
    "    tab[i] = accuracy_score(iris_y_test,k.predict(iris_X_test))\n",
    "    i+=1\n",
    "for x in tab:\n",
    "    if tab[x]==max(tab.values()):\n",
    "        print (\"The optimal k is : {0} with {1}\".format(x,tab[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a jupyter notebook with the following tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the iris dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use two other classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init\n",
    "clf = MultinomialNB(alpha=0.01)\n",
    "clf.fit(iris_X_train, iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_bayes = accuracy_score(iris_y_test,clf.predict(iris_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy is {0}\".format(accuracy_bayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2> Logistic Regression Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l1')\n",
    "lr.fit(iris_X_train, iris_y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_Regression= accuracy_score(iris_y_test,lr.predict(iris_X_test))\n",
    "print (\"Accuracy is {0}\".format(accuracy_Regression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3>Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree    \n",
    "dtree = tree.DecisionTreeClassifier()    \n",
    "dtree.fit(iris_X_train, iris_y_train)    \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_Decision= accuracy_score(iris_y_test,lr.predict(iris_X_test))\n",
    "print (\"Accuracy is {0}\".format(accuracy_Decision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cross-validation to evaluate the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn: 0.9869281045751634\n"
     ]
    }
   ],
   "source": [
    "knn_score=cross_val_score(knn,iris_X,iris_y)\n",
    "print(\"knn: {0}\".format(knn_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier: 0.960375816993464\n"
     ]
    }
   ],
   "source": [
    "decision_score = cross_val_score(dtree,iris_X,iris_y)\n",
    "print(\"Decision Tree Classifier: {0}\".format(decision_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier: 0.9399509803921569\n"
     ]
    }
   ],
   "source": [
    "regression_score = cross_val_score(lr,iris_X,iris_y)\n",
    "print(\"Logistic Regression Classifier: {0}\".format(regression_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier: 0.9607843137254902\n"
     ]
    }
   ],
   "source": [
    "bayes_score = cross_val_score(clf,iris_X,iris_y)\n",
    "print(\"Naive Bayes Classifier: {0}\".format(bayes_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn: 0.9869281045751634 with k=5 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
